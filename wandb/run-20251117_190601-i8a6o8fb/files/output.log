[34m[1mwandb[0m: wandb.init() called while a run is active and reinit is set to 'default', so returning the previous run.
/Users/eating/miniconda3/envs/py11/lib/python3.11/site-packages/gymnasium/envs/registration.py:512: DeprecationWarning: [33mWARN: The environment HalfCheetah-v4 is out of date. You should consider upgrading to version `v5`.[0m
  logger.deprecation(
Episode 0, Average Reward: -800.56, Entropy: 1.4189, Cumulative Steps: 1000
Episode 10, Average Reward: -765.53, Entropy: 1.4026, Cumulative Steps: 11000
Episode 20, Average Reward: -791.96, Entropy: 1.3722, Cumulative Steps: 21000
Episode 30, Average Reward: -687.83, Entropy: 1.3373, Cumulative Steps: 31000
Episode 40, Average Reward: -655.28, Entropy: 1.2999, Cumulative Steps: 41000
Episode 50, Average Reward: -564.87, Entropy: 1.2577, Cumulative Steps: 51000
Episode 60, Average Reward: -538.99, Entropy: 1.2195, Cumulative Steps: 61000
Episode 70, Average Reward: -419.58, Entropy: 1.1637, Cumulative Steps: 71000
Episode 80, Average Reward: -339.91, Entropy: 1.1144, Cumulative Steps: 81000
Episode 90, Average Reward: -251.85, Entropy: 1.0538, Cumulative Steps: 91000
Episode 100, Average Reward: -200.98, Entropy: 0.9989, Cumulative Steps: 101000
Models saved at episode 100
Episode 110, Average Reward: -131.20, Entropy: 0.9640, Cumulative Steps: 111000
Episode 120, Average Reward: -68.03, Entropy: 0.9423, Cumulative Steps: 121000
Episode 130, Average Reward: -116.12, Entropy: 0.9108, Cumulative Steps: 131000
Episode 140, Average Reward: 79.44, Entropy: 0.8659, Cumulative Steps: 141000
Episode 150, Average Reward: 233.29, Entropy: 0.8310, Cumulative Steps: 151000
Episode 160, Average Reward: 245.25, Entropy: 0.8070, Cumulative Steps: 161000
Episode 170, Average Reward: 339.98, Entropy: 0.7824, Cumulative Steps: 171000
Episode 180, Average Reward: 290.89, Entropy: 0.7558, Cumulative Steps: 181000
Episode 190, Average Reward: 468.44, Entropy: 0.7249, Cumulative Steps: 191000
Episode 200, Average Reward: 442.11, Entropy: 0.6859, Cumulative Steps: 201000
Models saved at episode 200
Episode 210, Average Reward: 661.55, Entropy: 0.6624, Cumulative Steps: 211000
Traceback (most recent call last):
  File "/Users/eating/Documents/sac/ppo/ppo.py", line 345, in <module>
    main()
  File "/Users/eating/Documents/sac/ppo/ppo.py", line 341, in main
    rewards = agent.train(seed=45, max_episodes=4000, save_interval=100)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/eating/Documents/sac/ppo/ppo.py", line 217, in train
    action, log_prob, entropy = self.get_action(state)
                                ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/eating/Documents/sac/ppo/ppo.py", line 104, in get_action
    mean, std = self.actor(state)
                ^^^^^^^^^^^^^^^^^
  File "/Users/eating/miniconda3/envs/py11/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/eating/miniconda3/envs/py11/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/eating/Documents/sac/ppo/ppo.py", line 52, in forward
    x = self.net(state)
        ^^^^^^^^^^^^^^^
  File "/Users/eating/miniconda3/envs/py11/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/eating/miniconda3/envs/py11/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/eating/miniconda3/envs/py11/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/Users/eating/miniconda3/envs/py11/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/eating/miniconda3/envs/py11/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/eating/miniconda3/envs/py11/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 144, in forward
    return F.relu(input, inplace=self.inplace)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/eating/miniconda3/envs/py11/lib/python3.11/site-packages/torch/nn/functional.py", line 1697, in relu
    result = torch.relu(input)
             ^^^^^^^^^^^^^^^^^
KeyboardInterrupt
