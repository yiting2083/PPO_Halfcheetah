[34m[1mwandb[0m: wandb.init() called while a run is active and reinit is set to 'default', so returning the previous run.
/Users/eating/miniconda3/envs/py11/lib/python3.11/site-packages/gymnasium/envs/registration.py:512: DeprecationWarning: [33mWARN: The environment HalfCheetah-v4 is out of date. You should consider upgrading to version `v5`.[0m
  logger.deprecation(
Episode 0, Average Reward: -800.56, Entropy: 1.4189, Cumulative steps: 1000
Episode 10, Average Reward: -765.53, Entropy: 1.4026, Cumulative steps: 11000
Episode 20, Average Reward: -791.96, Entropy: 1.3722, Cumulative steps: 21000
Episode 30, Average Reward: -687.83, Entropy: 1.3373, Cumulative steps: 31000
Episode 40, Average Reward: -655.28, Entropy: 1.2999, Cumulative steps: 41000
Episode 50, Average Reward: -564.87, Entropy: 1.2577, Cumulative steps: 51000
Episode 60, Average Reward: -538.99, Entropy: 1.2195, Cumulative steps: 61000
Episode 70, Average Reward: -419.58, Entropy: 1.1637, Cumulative steps: 71000
Episode 80, Average Reward: -339.91, Entropy: 1.1144, Cumulative steps: 81000
Episode 90, Average Reward: -251.85, Entropy: 1.0538, Cumulative steps: 91000
Episode 100, Average Reward: -200.98, Entropy: 0.9989, Cumulative steps: 101000
Models saved at episode 100
Episode 110, Average Reward: -131.20, Entropy: 0.9640, Cumulative steps: 111000
Episode 120, Average Reward: -68.03, Entropy: 0.9423, Cumulative steps: 121000
Episode 130, Average Reward: -116.12, Entropy: 0.9108, Cumulative steps: 131000
Episode 140, Average Reward: 79.44, Entropy: 0.8659, Cumulative steps: 141000
Episode 150, Average Reward: 233.29, Entropy: 0.8310, Cumulative steps: 151000
Episode 160, Average Reward: 245.25, Entropy: 0.8070, Cumulative steps: 161000
Episode 170, Average Reward: 339.98, Entropy: 0.7824, Cumulative steps: 171000
Episode 180, Average Reward: 290.89, Entropy: 0.7558, Cumulative steps: 181000
Episode 190, Average Reward: 468.44, Entropy: 0.7249, Cumulative steps: 191000
Episode 200, Average Reward: 442.11, Entropy: 0.6859, Cumulative steps: 201000
Models saved at episode 200
Episode 210, Average Reward: 661.55, Entropy: 0.6624, Cumulative steps: 211000
Episode 220, Average Reward: 550.43, Entropy: 0.6339, Cumulative steps: 221000
Episode 230, Average Reward: 600.49, Entropy: 0.6106, Cumulative steps: 231000
Episode 240, Average Reward: 653.05, Entropy: 0.5882, Cumulative steps: 241000
Episode 250, Average Reward: 823.43, Entropy: 0.5647, Cumulative steps: 251000
Episode 260, Average Reward: 905.39, Entropy: 0.5407, Cumulative steps: 261000
Episode 270, Average Reward: 996.33, Entropy: 0.5134, Cumulative steps: 271000
Episode 280, Average Reward: 993.70, Entropy: 0.4903, Cumulative steps: 281000
Episode 290, Average Reward: 780.48, Entropy: 0.4774, Cumulative steps: 291000
Episode 300, Average Reward: 1049.55, Entropy: 0.4592, Cumulative steps: 301000
Models saved at episode 300
Episode 310, Average Reward: 1041.97, Entropy: 0.4353, Cumulative steps: 311000
Episode 320, Average Reward: 922.46, Entropy: 0.4150, Cumulative steps: 321000
Episode 330, Average Reward: 1096.42, Entropy: 0.3973, Cumulative steps: 331000
Episode 340, Average Reward: 1097.38, Entropy: 0.3810, Cumulative steps: 341000
Episode 350, Average Reward: 1215.92, Entropy: 0.3551, Cumulative steps: 351000
Episode 360, Average Reward: 1355.33, Entropy: 0.3305, Cumulative steps: 361000
Episode 370, Average Reward: 1350.97, Entropy: 0.3176, Cumulative steps: 371000
Episode 380, Average Reward: 1380.65, Entropy: 0.2947, Cumulative steps: 381000
Episode 390, Average Reward: 1423.18, Entropy: 0.2764, Cumulative steps: 391000
Episode 400, Average Reward: 1431.57, Entropy: 0.2613, Cumulative steps: 401000
Models saved at episode 400
Episode 410, Average Reward: 1472.60, Entropy: 0.2480, Cumulative steps: 411000
Episode 420, Average Reward: 1416.36, Entropy: 0.2302, Cumulative steps: 421000
Episode 430, Average Reward: 1550.11, Entropy: 0.2156, Cumulative steps: 431000
Episode 440, Average Reward: 1616.73, Entropy: 0.1997, Cumulative steps: 441000
Episode 450, Average Reward: 1679.29, Entropy: 0.1795, Cumulative steps: 451000
Episode 460, Average Reward: 1672.91, Entropy: 0.1555, Cumulative steps: 461000
Episode 470, Average Reward: 1588.69, Entropy: 0.1333, Cumulative steps: 471000
Episode 480, Average Reward: 1693.17, Entropy: 0.1157, Cumulative steps: 481000
Episode 490, Average Reward: 1630.00, Entropy: 0.0990, Cumulative steps: 491000
Episode 500, Average Reward: 1684.76, Entropy: 0.0774, Cumulative steps: 501000
Models saved at episode 500
Episode 510, Average Reward: 1880.52, Entropy: 0.0589, Cumulative steps: 511000
Episode 520, Average Reward: 1906.31, Entropy: 0.0424, Cumulative steps: 521000
Episode 530, Average Reward: 1894.38, Entropy: 0.0246, Cumulative steps: 531000
Episode 540, Average Reward: 1506.18, Entropy: 0.0122, Cumulative steps: 541000
Episode 550, Average Reward: 1852.12, Entropy: 0.0022, Cumulative steps: 551000
Episode 560, Average Reward: 1892.08, Entropy: -0.0085, Cumulative steps: 561000
Episode 570, Average Reward: 1982.38, Entropy: -0.0201, Cumulative steps: 571000
Episode 580, Average Reward: 2065.70, Entropy: -0.0389, Cumulative steps: 581000
Episode 590, Average Reward: 2200.40, Entropy: -0.0614, Cumulative steps: 591000
Episode 600, Average Reward: 2143.17, Entropy: -0.0778, Cumulative steps: 601000
Models saved at episode 600
Episode 610, Average Reward: 2271.47, Entropy: -0.0936, Cumulative steps: 611000
Episode 620, Average Reward: 2355.00, Entropy: -0.1122, Cumulative steps: 621000
Episode 630, Average Reward: 2345.30, Entropy: -0.1325, Cumulative steps: 631000
Episode 640, Average Reward: 2335.65, Entropy: -0.1507, Cumulative steps: 641000
Episode 650, Average Reward: 2307.24, Entropy: -0.1671, Cumulative steps: 651000
Episode 660, Average Reward: 2366.28, Entropy: -0.1810, Cumulative steps: 661000
Episode 670, Average Reward: 2064.93, Entropy: -0.1969, Cumulative steps: 671000
Episode 680, Average Reward: 2432.92, Entropy: -0.2102, Cumulative steps: 681000
Episode 690, Average Reward: 2169.96, Entropy: -0.2200, Cumulative steps: 691000
Episode 700, Average Reward: 2394.08, Entropy: -0.2276, Cumulative steps: 701000
Models saved at episode 700
Episode 710, Average Reward: 2471.60, Entropy: -0.2330, Cumulative steps: 711000
Episode 720, Average Reward: 2133.39, Entropy: -0.2463, Cumulative steps: 721000
Episode 730, Average Reward: 2380.82, Entropy: -0.2540, Cumulative steps: 731000
Episode 740, Average Reward: 2448.63, Entropy: -0.2644, Cumulative steps: 741000
Episode 750, Average Reward: 2553.03, Entropy: -0.2779, Cumulative steps: 751000
Episode 760, Average Reward: 2609.16, Entropy: -0.2866, Cumulative steps: 761000
Episode 770, Average Reward: 2683.27, Entropy: -0.3039, Cumulative steps: 771000
Episode 780, Average Reward: 2581.20, Entropy: -0.3158, Cumulative steps: 781000
Episode 790, Average Reward: 2623.89, Entropy: -0.3278, Cumulative steps: 791000
Episode 800, Average Reward: 2637.21, Entropy: -0.3399, Cumulative steps: 801000
Models saved at episode 800
Episode 810, Average Reward: 2604.00, Entropy: -0.3482, Cumulative steps: 811000
Episode 820, Average Reward: 2625.75, Entropy: -0.3602, Cumulative steps: 821000
Episode 830, Average Reward: 2672.94, Entropy: -0.3772, Cumulative steps: 831000
Episode 840, Average Reward: 2672.82, Entropy: -0.3943, Cumulative steps: 841000
Episode 850, Average Reward: 2769.73, Entropy: -0.4064, Cumulative steps: 851000
Episode 860, Average Reward: 2883.08, Entropy: -0.4206, Cumulative steps: 861000
Episode 870, Average Reward: 2878.06, Entropy: -0.4325, Cumulative steps: 871000
Episode 880, Average Reward: 2835.51, Entropy: -0.4469, Cumulative steps: 881000
Episode 890, Average Reward: 2940.16, Entropy: -0.4625, Cumulative steps: 891000
Episode 900, Average Reward: 2990.84, Entropy: -0.4728, Cumulative steps: 901000
Models saved at episode 900
Episode 910, Average Reward: 2940.86, Entropy: -0.4814, Cumulative steps: 911000
Episode 920, Average Reward: 3007.94, Entropy: -0.4982, Cumulative steps: 921000
Episode 930, Average Reward: 2974.41, Entropy: -0.5126, Cumulative steps: 931000
Episode 940, Average Reward: 3032.76, Entropy: -0.5221, Cumulative steps: 941000
Episode 950, Average Reward: 2952.28, Entropy: -0.5258, Cumulative steps: 951000
Episode 960, Average Reward: 3032.20, Entropy: -0.5283, Cumulative steps: 961000
Episode 970, Average Reward: 2978.48, Entropy: -0.5338, Cumulative steps: 971000
Episode 980, Average Reward: 3032.24, Entropy: -0.5396, Cumulative steps: 981000
Episode 990, Average Reward: 2955.57, Entropy: -0.5442, Cumulative steps: 991000
Episode 1000, Average Reward: 3060.76, Entropy: -0.5500, Cumulative steps: 1001000
Models saved at episode 1000
Episode 1010, Average Reward: 3071.09, Entropy: -0.5534, Cumulative steps: 1011000
Episode 1020, Average Reward: 2977.72, Entropy: -0.5584, Cumulative steps: 1021000
Episode 1030, Average Reward: 2796.95, Entropy: -0.5613, Cumulative steps: 1031000
Episode 1040, Average Reward: 2943.90, Entropy: -0.5626, Cumulative steps: 1041000
Episode 1050, Average Reward: 2990.80, Entropy: -0.5656, Cumulative steps: 1051000
Episode 1060, Average Reward: 3082.65, Entropy: -0.5721, Cumulative steps: 1061000
Episode 1070, Average Reward: 3115.32, Entropy: -0.5812, Cumulative steps: 1071000
Episode 1080, Average Reward: 3196.63, Entropy: -0.5901, Cumulative steps: 1081000
Episode 1090, Average Reward: 3204.85, Entropy: -0.6025, Cumulative steps: 1091000
Episode 1100, Average Reward: 2858.76, Entropy: -0.6149, Cumulative steps: 1101000
Models saved at episode 1100
Episode 1110, Average Reward: 2532.32, Entropy: -0.6201, Cumulative steps: 1111000
Episode 1120, Average Reward: 2937.95, Entropy: -0.6194, Cumulative steps: 1121000
Episode 1130, Average Reward: 3128.22, Entropy: -0.6221, Cumulative steps: 1131000
Episode 1140, Average Reward: 3150.77, Entropy: -0.6294, Cumulative steps: 1141000
Episode 1150, Average Reward: 3174.22, Entropy: -0.6371, Cumulative steps: 1151000
Episode 1160, Average Reward: 3139.49, Entropy: -0.6427, Cumulative steps: 1161000
Episode 1170, Average Reward: 3202.76, Entropy: -0.6478, Cumulative steps: 1171000
Episode 1180, Average Reward: 3065.24, Entropy: -0.6521, Cumulative steps: 1181000
Episode 1190, Average Reward: 2753.45, Entropy: -0.6552, Cumulative steps: 1191000
Episode 1200, Average Reward: 2950.69, Entropy: -0.6639, Cumulative steps: 1201000
Models saved at episode 1200
Episode 1210, Average Reward: 2569.06, Entropy: -0.6707, Cumulative steps: 1211000
Episode 1220, Average Reward: 2950.70, Entropy: -0.6734, Cumulative steps: 1221000
Episode 1230, Average Reward: 3154.27, Entropy: -0.6750, Cumulative steps: 1231000
Episode 1240, Average Reward: 3241.28, Entropy: -0.6793, Cumulative steps: 1241000
Episode 1250, Average Reward: 3222.57, Entropy: -0.6866, Cumulative steps: 1251000
Episode 1260, Average Reward: 3209.63, Entropy: -0.6924, Cumulative steps: 1261000
Episode 1270, Average Reward: 3361.50, Entropy: -0.6968, Cumulative steps: 1271000
Episode 1280, Average Reward: 3211.03, Entropy: -0.7028, Cumulative steps: 1281000
Episode 1290, Average Reward: 3151.74, Entropy: -0.7069, Cumulative steps: 1291000
Episode 1300, Average Reward: 3224.36, Entropy: -0.7130, Cumulative steps: 1301000
Models saved at episode 1300
Episode 1310, Average Reward: 3268.36, Entropy: -0.7249, Cumulative steps: 1311000
Episode 1320, Average Reward: 3055.60, Entropy: -0.7342, Cumulative steps: 1321000
Episode 1330, Average Reward: 2989.04, Entropy: -0.7445, Cumulative steps: 1331000
Episode 1340, Average Reward: 3107.61, Entropy: -0.7485, Cumulative steps: 1341000
Episode 1350, Average Reward: 3222.71, Entropy: -0.7515, Cumulative steps: 1351000
Episode 1360, Average Reward: 3080.23, Entropy: -0.7522, Cumulative steps: 1361000
Episode 1370, Average Reward: 2889.62, Entropy: -0.7565, Cumulative steps: 1371000
Episode 1380, Average Reward: 2711.83, Entropy: -0.7587, Cumulative steps: 1381000
Episode 1390, Average Reward: 2826.13, Entropy: -0.7618, Cumulative steps: 1391000
Episode 1400, Average Reward: 2866.66, Entropy: -0.7648, Cumulative steps: 1401000
Models saved at episode 1400
Episode 1410, Average Reward: 3078.17, Entropy: -0.7685, Cumulative steps: 1411000
Episode 1420, Average Reward: 3153.48, Entropy: -0.7746, Cumulative steps: 1421000
Episode 1430, Average Reward: 3229.03, Entropy: -0.7815, Cumulative steps: 1431000
Episode 1440, Average Reward: 3215.04, Entropy: -0.7895, Cumulative steps: 1441000
Episode 1450, Average Reward: 3235.96, Entropy: -0.7959, Cumulative steps: 1451000
Episode 1460, Average Reward: 3328.79, Entropy: -0.8050, Cumulative steps: 1461000
Episode 1470, Average Reward: 3347.60, Entropy: -0.8146, Cumulative steps: 1471000
Episode 1480, Average Reward: 3308.63, Entropy: -0.8231, Cumulative steps: 1481000
Episode 1490, Average Reward: 3383.43, Entropy: -0.8344, Cumulative steps: 1491000
Episode 1500, Average Reward: 3339.13, Entropy: -0.8474, Cumulative steps: 1501000
Models saved at episode 1500
Episode 1510, Average Reward: 3443.72, Entropy: -0.8615, Cumulative steps: 1511000
Episode 1520, Average Reward: 3511.07, Entropy: -0.8663, Cumulative steps: 1521000
Episode 1530, Average Reward: 3454.35, Entropy: -0.8685, Cumulative steps: 1531000
Episode 1540, Average Reward: 3398.21, Entropy: -0.8758, Cumulative steps: 1541000
Episode 1550, Average Reward: 3459.36, Entropy: -0.8864, Cumulative steps: 1551000
Episode 1560, Average Reward: 3441.88, Entropy: -0.8947, Cumulative steps: 1561000
Episode 1570, Average Reward: 3385.09, Entropy: -0.9044, Cumulative steps: 1571000
Episode 1580, Average Reward: 3476.39, Entropy: -0.9101, Cumulative steps: 1581000
Episode 1590, Average Reward: 3454.34, Entropy: -0.9189, Cumulative steps: 1591000
Episode 1600, Average Reward: 3518.26, Entropy: -0.9282, Cumulative steps: 1601000
Models saved at episode 1600
Episode 1610, Average Reward: 3470.40, Entropy: -0.9342, Cumulative steps: 1611000
Episode 1620, Average Reward: 3494.71, Entropy: -0.9437, Cumulative steps: 1621000
Episode 1630, Average Reward: 3540.61, Entropy: -0.9508, Cumulative steps: 1631000
Episode 1640, Average Reward: 3538.10, Entropy: -0.9612, Cumulative steps: 1641000
Episode 1650, Average Reward: 3488.63, Entropy: -0.9666, Cumulative steps: 1651000
Episode 1660, Average Reward: 3379.37, Entropy: -0.9699, Cumulative steps: 1661000
Episode 1670, Average Reward: 3393.25, Entropy: -0.9719, Cumulative steps: 1671000
Episode 1680, Average Reward: 3423.70, Entropy: -0.9741, Cumulative steps: 1681000
Episode 1690, Average Reward: 3465.21, Entropy: -0.9782, Cumulative steps: 1691000
Episode 1700, Average Reward: 3452.20, Entropy: -0.9808, Cumulative steps: 1701000
Models saved at episode 1700
Episode 1710, Average Reward: 3469.62, Entropy: -0.9807, Cumulative steps: 1711000
Episode 1720, Average Reward: 3395.75, Entropy: -0.9816, Cumulative steps: 1721000
Episode 1730, Average Reward: 3547.38, Entropy: -0.9839, Cumulative steps: 1731000
Episode 1740, Average Reward: 3545.77, Entropy: -0.9899, Cumulative steps: 1741000
Episode 1750, Average Reward: 3472.75, Entropy: -0.9980, Cumulative steps: 1751000
Episode 1760, Average Reward: 3542.07, Entropy: -1.0010, Cumulative steps: 1761000
Episode 1770, Average Reward: 3547.71, Entropy: -1.0066, Cumulative steps: 1771000
Episode 1780, Average Reward: 3463.12, Entropy: -1.0108, Cumulative steps: 1781000
Episode 1790, Average Reward: 3486.65, Entropy: -1.0216, Cumulative steps: 1791000
Episode 1800, Average Reward: 3487.76, Entropy: -1.0300, Cumulative steps: 1801000
Models saved at episode 1800
Episode 1810, Average Reward: 3561.94, Entropy: -1.0371, Cumulative steps: 1811000
Episode 1820, Average Reward: 3456.73, Entropy: -1.0407, Cumulative steps: 1821000
Episode 1830, Average Reward: 3349.87, Entropy: -1.0469, Cumulative steps: 1831000
Episode 1840, Average Reward: 3192.90, Entropy: -1.0495, Cumulative steps: 1841000
Episode 1850, Average Reward: 3245.23, Entropy: -1.0515, Cumulative steps: 1851000
Episode 1860, Average Reward: 3302.33, Entropy: -1.0552, Cumulative steps: 1861000
Episode 1870, Average Reward: 3380.48, Entropy: -1.0611, Cumulative steps: 1871000
Episode 1880, Average Reward: 3436.25, Entropy: -1.0667, Cumulative steps: 1881000
Episode 1890, Average Reward: 3305.08, Entropy: -1.0682, Cumulative steps: 1891000
Episode 1900, Average Reward: 3389.81, Entropy: -1.0736, Cumulative steps: 1901000
Models saved at episode 1900
Episode 1910, Average Reward: 3279.65, Entropy: -1.0777, Cumulative steps: 1911000
Episode 1920, Average Reward: 3269.90, Entropy: -1.0795, Cumulative steps: 1921000
Episode 1930, Average Reward: 3459.33, Entropy: -1.0830, Cumulative steps: 1931000
Episode 1940, Average Reward: 3384.46, Entropy: -1.0897, Cumulative steps: 1941000
Episode 1950, Average Reward: 3359.29, Entropy: -1.0932, Cumulative steps: 1951000
Episode 1960, Average Reward: 3411.06, Entropy: -1.0955, Cumulative steps: 1961000
Episode 1970, Average Reward: 3206.37, Entropy: -1.0965, Cumulative steps: 1971000
Episode 1980, Average Reward: 3539.28, Entropy: -1.0974, Cumulative steps: 1981000
Episode 1990, Average Reward: 3546.33, Entropy: -1.0980, Cumulative steps: 1991000
Traceback (most recent call last):
  File "/Users/eating/Documents/sac/ppo/ppo.py", line 349, in <module>
    main()
  File "/Users/eating/Documents/sac/ppo/ppo.py", line 345, in main
    rewards = agent.train(seed=45, max_episodes=4000, save_interval=100)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/eating/Documents/sac/ppo/ppo.py", line 217, in train
    action, log_prob, entropy = self.get_action(state)
                                ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/eating/Documents/sac/ppo/ppo.py", line 107, in get_action
    log_prob = dist.log_prob(action).sum(dim=-1)
               ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/eating/miniconda3/envs/py11/lib/python3.11/site-packages/torch/distributions/normal.py", line 95, in log_prob
    else self.scale.log()
         ^^^^^^^^^^^^^^^^
KeyboardInterrupt
